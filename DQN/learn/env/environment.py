import gym
import numpy as np
from gym import spaces

class dqnEnvironment(gym.Env):
    metadata = {'render.modes': ['human', 'ansi']}

    def __init__(self):
        super(dqnEnvironment, self).__init__()
        
        # Load the map
        self.MAP = np.loadtxt('../processdata/newmap.txt')
        self.line = len(self.MAP)
        
        # Define action space
        self.action_space = spaces.Discrete(self.line) 

        # Define observation space
        # Assuming the observation space is a single integer representing the position
        self.observation_space = spaces.Discrete(self.line)

        # Initialize the environment
        self.reset()

    def reset(self, seed=None, options=None):
        if seed is not None:
            self.seed(seed)
        
        # parameters initialize
        self.pos = 0
        self.goal = self.line - 1
        self.done = False
        self.steps = 0
        return self._observe(), {}

    def step(self, action):
        self.next_state = action
        self.state = [self.pos, self.next_state]

        self.pos = self.next_state
        self.steps += 1

        observation = self._observe()
        reward = self._get_reward()
        self.done = self._is_done()
        info = {"steps": self.steps}

        return observation, reward, self.done, info

    def _get_reward(self):
        return self.MAP[self.pos, self.next_state]

    def _observe(self):
        return self.pos

    def _is_done(self):
        return self.pos == self.goal

    def render(self, mode='human'):
        if mode == 'human':
            print(f"Position: {self.pos}")
        elif mode == 'ansi':
            return f"Position: {self.pos}"

    def close(self):
        pass

    def seed(self, seed=None):
        np.random.seed(seed)

